{"cells":[{"cell_type":"markdown","source":["#EN-VI Machine Translation using Pre-Trained Language Models\n","**Dataset: IWSLT15-en-vi**\n","\n","**thai.nq07@gmail.com**"],"metadata":{"id":"FQtRi2VzO8UE"},"id":"FQtRi2VzO8UE"},{"cell_type":"code","execution_count":null,"id":"7175d901","metadata":{"tags":[],"id":"7175d901"},"outputs":[],"source":["!pip install -q datasets sacrebleu accelerate>=0.20.1"]},{"cell_type":"code","execution_count":2,"id":"c0bb7005","metadata":{"tags":[],"id":"c0bb7005","executionInfo":{"status":"ok","timestamp":1708187042252,"user_tz":-420,"elapsed":15606,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa88f2f0-c69e-4b3b-9136-e1250df1220f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n","  warnings.warn(\n","WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12020, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_tf_utils.py:24: FutureWarning: Importing `TFGenerationMixin` from `src/transformers/generation_tf_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import TFGenerationMixin` instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation_flax_utils.py:24: FutureWarning: Importing `FlaxGenerationMixin` from `src/transformers/generation_flax_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import FlaxGenerationMixin` instead.\n","  warnings.warn(\n"]}],"source":["import os\n","import numpy as np\n","\n","import sacrebleu\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","from datasets import load_dataset, load_metric\n","from transformers import *"]},{"cell_type":"markdown","source":["##1.Prepare Data"],"metadata":{"id":"CARf8Jgt_t_6"},"id":"CARf8Jgt_t_6"},{"cell_type":"code","execution_count":3,"id":"877686dc","metadata":{"tags":[],"id":"877686dc","executionInfo":{"status":"ok","timestamp":1708187042252,"user_tz":-420,"elapsed":4,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["class NMTDataset(Dataset):\n","    def __init__(self, cfg, data_type=\"train\"):\n","        super().__init__()\n","        self.cfg = cfg\n","\n","        self.src_texts, self.tgt_texts = self.read_data(data_type)\n","\n","        self.src_input_ids, self.src_attention_mask = self.texts_to_sequences(self.src_texts)\n","        self.tgt_input_ids, self.tgt_attention_mask, self.labels = self.texts_to_sequences(\n","            self.tgt_texts,\n","            is_src=False\n","        )\n","\n","    def read_data(self, data_type):\n","        data = load_dataset(\n","            \"mt_eng_vietnamese\",\n","            \"iwslt2015-en-vi\",\n","            split=data_type\n","        )\n","        src_texts = [sample[\"translation\"][self.cfg.src_lang] for sample in data]\n","        tgt_texts = [sample[\"translation\"][self.cfg.tgt_lang] for sample in data]\n","        return src_texts, tgt_texts\n","\n","    def texts_to_sequences(self, texts, is_src=True):\n","        if is_src:\n","            src_inputs = self.cfg.src_tokenizer(\n","                texts,\n","                padding='max_length',\n","                truncation=True,\n","                max_length=self.cfg.src_max_len,\n","                return_tensors='pt'\n","            )\n","            return (\n","                src_inputs.input_ids,\n","                src_inputs.attention_mask\n","            )\n","\n","        else:\n","            if self.cfg.add_special_tokens:\n","                texts = [\n","                    ' '.join([\n","                        self.cfg.tgt_tokenizer.bos_token,\n","                        text,\n","                        self.cfg.tgt_tokenizer.eos_token\n","                        ])\n","                    for text in texts\n","                ]\n","            tgt_inputs = self.cfg.tgt_tokenizer(\n","                texts,\n","                padding='max_length',\n","                truncation=True,\n","                max_length=self.cfg.tgt_max_len,\n","                return_tensors='pt'\n","            )\n","\n","            labels = tgt_inputs.input_ids.numpy().tolist()\n","            labels = [\n","                [\n","                    -100 if token_id == self.cfg.tgt_tokenizer.pad_token_id else token_id\n","                    for token_id in label\n","                ]\n","                for label in labels\n","            ]\n","\n","            labels = torch.LongTensor(labels)\n","\n","            return (\n","                tgt_inputs.input_ids,\n","                tgt_inputs.attention_mask,\n","                labels\n","            )\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"input_ids\": self.src_input_ids[idx],\n","            \"attention_mask\": self.src_attention_mask[idx],\n","            \"decoder_input_ids\": self.tgt_input_ids[idx],\n","            \"decoder_attention_mask\": self.tgt_attention_mask[idx],\n","            \"labels\": self.labels[idx]\n","        }\n","\n","    def __len__(self):\n","        return np.shape(self.src_input_ids)[0]"]},{"cell_type":"markdown","source":["##2.Load Tokenizer and Model"],"metadata":{"id":"ZK0pjhljKWNp"},"id":"ZK0pjhljKWNp"},{"cell_type":"code","execution_count":4,"id":"0b17c136","metadata":{"tags":[],"id":"0b17c136","executionInfo":{"status":"ok","timestamp":1708187046503,"user_tz":-420,"elapsed":3,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","    return preds, labels\n","\n","def load_tokenizer(model_name_or_path):\n","    if 'bert' in model_name_or_path.split('-'):\n","        return BertTokenizerFast.from_pretrained(model_name_or_path)\n","    elif 'gpt2' in model_name_or_path.split('-'):\n","        return GPT2TokenizerFast.from_pretrained(model_name_or_path)\n","    else:\n","        return AutoTokenizer.from_pretrained(model_name_or_path)"]},{"cell_type":"code","execution_count":5,"id":"97b73613","metadata":{"tags":[],"id":"97b73613","executionInfo":{"status":"ok","timestamp":1708187049283,"user_tz":-420,"elapsed":3,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["class Manager():\n","    def __init__(self, cfg, is_train=True):\n","        self.cfg = cfg\n","\n","        print(\"Loading Tokenizer...\")\n","        self.get_tokenizer()\n","\n","        print(\"Loading Model...\")\n","        self.get_model()\n","\n","        print(\"Loading Metric...\")\n","        self.bleu_metric = load_metric(\"sacrebleu\")\n","\n","        print(\"Check Save Model Path\")\n","        if not os.path.exists(self.cfg.ckpt_dir):\n","            os.mkdir(self.cfg.ckpt_dir)\n","\n","        if is_train:\n","            # Load dataloaders\n","            print(\"Loading Dataset...\")\n","            self.train_dataset = NMTDataset(self.cfg, data_type=\"train\")\n","            self.valid_dataset = NMTDataset(self.cfg, data_type=\"validation\")\n","\n","        print(\"Setting finished.\")\n","\n","    def get_tokenizer(self):\n","        if self.cfg.load_model_from_path:\n","            self.cfg.src_tokenizer = load_tokenizer(self.cfg.ckpt_dir)\n","            self.cfg.tgt_tokenizer = load_tokenizer(self.cfg.ckpt_dir)\n","        else:\n","            self.cfg.src_tokenizer = load_tokenizer(self.cfg.src_model_name)\n","            self.cfg.tgt_tokenizer = load_tokenizer(self.cfg.tgt_model_name)\n","            if \"bert\" in self.cfg.tgt_model_name.split('-'):\n","                self.cfg.add_special_tokens = False\n","                self.cfg.bos_token_id = self.cfg.tgt_tokenizer.cls_token_id\n","                self.cfg.eos_token_id = self.cfg.tgt_tokenizer.sep_token_id\n","                self.cfg.pad_token_id = self.cfg.tgt_tokenizer.pad_token_id\n","            else:\n","                self.cfg.add_special_tokens = True\n","                self.cfg.tgt_tokenizer.add_special_tokens(\n","                    {\n","                        \"bos_token\": \"[BOS]\",\n","                        \"eos_token\": \"[EOS]\",\n","                        \"pad_token\": \"[PAD]\"\n","                    }\n","                )\n","                self.cfg.bos_token_id = self.cfg.tgt_tokenizer.bos_token_id\n","                self.cfg.eos_token_id = self.cfg.tgt_tokenizer.eos_token_id\n","                self.cfg.pad_token_id = self.cfg.tgt_tokenizer.pad_token_id\n","        self.cfg.src_tokenizer.save_pretrained(\n","                os.path.join(self.cfg.ckpt_dir, f\"{self.cfg.src_lang}_tokenizer_{cfg.src_model_name}\")\n","            )\n","\n","        self.cfg.tgt_tokenizer.save_pretrained(\n","                os.path.join(self.cfg.ckpt_dir, f\"{self.cfg.tgt_lang}_tokenizer_{cfg.tgt_model_name}\")\n","            )\n","\n","    def get_model(self):\n","        if self.cfg.load_model_from_path:\n","            save_model_path = os.path.join(self.cfg.ckpt_dir, self.cfg.ckpt_name)\n","            self.model = EncoderDecoderModel.from_pretrained(save_model_path)\n","        else:\n","            self.model = EncoderDecoderModel.from_encoder_decoder_pretrained(\n","                self.cfg.src_model_name,\n","                self.cfg.tgt_model_name\n","            )\n","            self.model.decoder.resize_token_embeddings(len(self.cfg.tgt_tokenizer))\n","            self.model.config.decoder_start_token_id = self.cfg.bos_token_id\n","            self.model.config.eos_token_id = self.cfg.eos_token_id\n","            self.model.config.pad_token_id = self.cfg.pad_token_id\n","            self.model.config.vocab_size = len(self.cfg.tgt_tokenizer)\n","            self.model.config.max_length = self.cfg.max_length_decoder\n","            self.model.config.min_length = self.cfg.min_length_decoder\n","            self.model.config.no_repeat_ngram_size = 3\n","            self.model.config.early_stopping = True\n","            self.model.config.length_penalty = 2.0\n","            self.model.config.num_beams = self.cfg.beam_size\n","\n","    def train(self):\n","        print(\"Training...\")\n","        if self.cfg.use_eval_steps:\n","            training_args = Seq2SeqTrainingArguments(\n","                predict_with_generate=True,\n","                evaluation_strategy=\"steps\",\n","                save_strategy='steps',\n","                save_steps=self.cfg.eval_steps,\n","                eval_steps=self.cfg.eval_steps,\n","                output_dir=self.cfg.ckpt_dir,\n","                per_device_train_batch_size=self.cfg.train_batch_size,\n","                per_device_eval_batch_size=self.cfg.eval_batch_size,\n","                learning_rate=self.cfg.learning_rate,\n","                weight_decay=0.005,\n","                num_train_epochs=self.cfg.num_train_epochs\n","            )\n","        else:\n","            training_args = Seq2SeqTrainingArguments(\n","                predict_with_generate=True,\n","                evaluation_strategy=\"epoch\",\n","                save_strategy='epoch',\n","                output_dir=self.cfg.ckpt_dir,\n","                per_device_train_batch_size=self.cfg.train_batch_size,\n","                per_device_eval_batch_size=self.cfg.eval_batch_size,\n","                learning_rate=self.cfg.learning_rate,\n","                weight_decay=0.005,\n","                num_train_epochs=self.cfg.num_train_epochs\n","            )\n","\n","        data_collator = DataCollatorForSeq2Seq(\n","            self.cfg.tgt_tokenizer,\n","            model=self.model\n","        )\n","\n","        trainer = Seq2SeqTrainer(\n","            self.model,\n","            training_args,\n","            train_dataset=self.train_dataset,\n","            eval_dataset=self.valid_dataset,\n","            data_collator=data_collator,\n","            tokenizer=self.cfg.tgt_tokenizer,\n","            compute_metrics=self.compute_metrics\n","        )\n","\n","        trainer.train()\n","\n","    def compute_metrics(self, eval_preds):\n","        preds, labels = eval_preds\n","        if isinstance(preds, tuple):\n","            preds = preds[0]\n","        decoded_preds = self.cfg.tgt_tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","        labels = np.where(labels != -100, labels, self.cfg.tgt_tokenizer.pad_token_id)\n","        decoded_labels = self.cfg.tgt_tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","        result = self.bleu_metric.compute(\n","            predictions=decoded_preds,\n","            references=decoded_labels\n","        )\n","\n","        result = {\"bleu_score\": result[\"score\"]}\n","\n","        prediction_lens = [np.count_nonzero(pred != self.cfg.tgt_tokenizer.pad_token_id) for pred in preds]\n","        result[\"gen_len\"] = np.mean(prediction_lens)\n","        result = {k: round(v, 4) for k, v in result.items()}\n","\n","        return result"]},{"cell_type":"markdown","source":["##3.Config"],"metadata":{"id":"NLQcCekFKc67"},"id":"NLQcCekFKc67"},{"cell_type":"code","execution_count":6,"id":"268232ec","metadata":{"tags":[],"id":"268232ec","executionInfo":{"status":"ok","timestamp":1708187054221,"user_tz":-420,"elapsed":4,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["class BaseConfig:\n","    \"\"\" base Encoder Decoder config \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","\n","class NMTConfig(BaseConfig):\n","    # Data\n","    src_lang = 'en'\n","    tgt_lang = 'vi'\n","    src_max_len = 75\n","    tgt_max_len = 75\n","\n","    # Model\n","    src_model_name = \"bert-base-multilingual-cased\"\n","    tgt_model_name = \"bert-base-multilingual-cased\"\n","\n","    # Training\n","    load_model_from_path = False\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    learning_rate = 3e-5\n","    train_batch_size = 16\n","    eval_batch_size = 8\n","    num_train_epochs = 5\n","    ckpt_dir = src_model_name + '_to_' + tgt_model_name\n","    use_eval_steps = False\n","    eval_steps = 2000\n","\n","    # Inference\n","    max_length_decoder = 75\n","    min_length_decoder = 25\n","    beam_size = 1\n","\n","cfg = NMTConfig()"]},{"cell_type":"markdown","source":["##4.Training"],"metadata":{"id":"Oq5pd77pKf1N"},"id":"Oq5pd77pKf1N"},{"cell_type":"code","execution_count":7,"id":"ad842440","metadata":{"scrolled":true,"tags":[],"id":"ad842440","outputId":"3e1314eb-6637-4469-ce00-d3fea7285d5e","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8ec9bd40e0684bb69eb5961e2a547c85","a5d0396b517b44f29a6dd1db67e90eed","a5ea01cb256049eb9d9f888616725f60","237bb8d7735448deb76a7b98dbbc3147","baf9ed9be5384c0496e15150dbcfc808","65f43b262abb43ebb8a89cdbec780f34","6320d65752f74c76b5e93c25edfe508e","f516628305924da9874f624d72e9c99f","9bc6b01585b747b89f9aebf73b7795c4","c8610e699e1645a1bc9dd40740ecd377","27afd50ff61742d8947a5d1215b9f357","9c9790f6f1af40c390b9126c729d3ae5","8f1fe71e174d4050b002267cb20f85d9","df78999befef439b839daccc30bbb527","a4ca6d9107ed4b5a8303460281611fb0","58b5c51d02b2446fbdeb99e09409bf1f","863d0bd13ecd478cb7e40c5c5ac68dd7","8c72650f6e92450cb1fc621d59b2d636","bf6a864db3864922a6d0562fbdeda4bc","a4152f23a75848f48c48c96ddb4d2fcc","eadbe6e43d07446d8132a4fa1d0faedf","91af7ce0a1f1498888871bd47f854618","1a3768c25a8f4e51822539b412ed0d70","3b2b7e1788a144fc80b06a3342402c53","9efdcf9d4af14535bfb4b872acbfc1ab","78f0fcb8cefd488d8fd489792a547556","b2721479ab96432d8e4c27a66165a331","136fdace19284b718a7e434afb767fbf","08ecb6a1b3ee473cbc322ec5d910f2cc","0119e423ccd14a6fa123cd033c12b382","8cb16a5aa5d84a7f9ff6091d34e109b7","62691a2f4d424aa28d02648b8631e42a","4396f568e0e94f6ea4bd6782b3929a00","f8d2d48a72574832950daeeb72ac074a","ed09a42689e94bb99fef042760441258","246371b3ff5b47adadb74fd748faad97","e8d8cda868e14fcda5411827ab972f48","e14447fc708641d0877763d7ada72e9b","67d6af9ec5f8447485a68bf73bd2ef06","9ed49c76dd934036822a22a22b31c8be","47745f113d16493ba57d3d84b7b37846","f9f6f6c959664385aea8781858c21172","89abf96e583f4fe3935b73c2b13bc0fa","da256cab8e1f49ec99257c5daadcb795","04b9ae4556d04d31ac24d2b2400d4c53","642bdb53ea4c434485c382c7827f15ef","d233b89b47424f55ae63dc86e71fbad5","cc55c5b310b443198eeff939175ba244","5822736dcf614680add01abee3dd1285","d6b2059bf1c84b97b21dbbfdea58123a","577fa092c335498b985109cfad6012af","256dbce836fc41e8952d49588e3d381e","e2e16b502b8d41129019f817581e597a","d40ccee378fb4b6c93bd0e683e010e93","bf0eacaa9f0948899197ff6bf242c2df","117a1867471041178577a119e12a0102","787c08d264c941c28c702046ada38291","1f5cef4b3daa4c688585e955ea9600f3","410d3d7a70f2451ead0686bf0888abe2","51cd0825bda84515bc8aa2f20195fc1a","df13e35455e341d89a87a251fa09dc3c","6c5fb78927c946978d131a17fde72763","1cead66be57349faafe328ecd513e0f5","b235face4090455abf8a823ba4b2a65c","77731caf83e8469ab5b3d7ee7344d3ee","5eff238c117f4e169d3242de6b250cc2","a726daf0a44640209e4e45ffecf7ab4c","e1f97e7cbfd6470da83de3a9ac06b5f7","8a9903588be84c7680901d88367e1a5b","d9be5377b9084a65b07fdf9dbede434e","04cfa0e8b35d4cd690738a5fcd43d48c","547ebb48ce664bb9a9ad1af05852320f","42a9b3ce657649fcb8a14f8dc81cb4ca","c1612378c0484914ab6fd36608030e14","9a16aaa8e73d4a98b3c803d6f7024c68","ace9caa4277245be9d181f7d04cdda20","c687347942ef41939423628af1ea2036","faad2b28d7e04177a44c49fccf1718fe","21c5bef2ce0348ecbb8e13888db44657","fc86b011b2554cd2a36e4cc7fb8a0682","ca503beae4e9495295ea37e95fb50ef8","36721a951dec414aa9316278d511d751","eb37abb3142b467983df816d71734401","933c05f7d1cb414b9ec11088c58bcfd6","43f96e2da6db44b8b3b41ff7351db172","12ce7c70aced41d7aa1fbee673dda4bd","db0082eef7c3477bb8e8dc3da73fde37","c0297cc040394ec7afeaf7d813c86b57","fc6347a28f2947c2b1710f82ac92c364","92216fdc65db4010b65d5a576f185a96","9a9cb72eb8a14e118aea9fa66e2cd465","b6baf914a86a4e20baf797bf12a18b73","d8be81037a6943afa285c7d2fcfef136","1ad48a346ce64799a7b68b6c2395e884","246ecc92d2f34eab816d804bf6209e46","8361d37640ef42fda3734a7f9f9a62d1","7561171fabfc4230ae00be38bfced54f","7f2047b289f1457395c3b43d23eb88a6","8568d83d656e4d588db280ce6b01af8e","61f89f0a224c441fa8be22680b3b3d0a","4ad1a61e94054c75802d7626ea26daae","e4c111798b164d2a812f30b488aaaf1d","ebad4741511d402cb539ab31b5626043","8dfc21ca5d8544febd1162ba25ee9a2f","4d413a464a5c40879207012c9cbd29e9","125f1e821bfb4f42a4e4fbe4ea79b8ab","496dbe2140a842bda7ec953b423253d5","0e3576804e524e6db3cba29f6f114c5f","9a975156302842588b2811f45cf13cac","bd5130966d25440894d69bd7ab522a92","e058ffc0291f462eb0094cbb9be89fe8","231378acab0042abae76b1852f422510","34c0065d91af4f85aa2a85192ceacf0c","c84fdd5ca2e14b13b729a54a8aed20bc","6499c3e271c4445189f001d04d65b187","afb14a37bec14dcaaef9e2e0e339b9ef","237486d0561a406aa00eb1e05d5d7e38","fd3ffb8751b04decb617d0fe21671f35","33cb80778dff40979ee383539d3ca581","6a493153e1ff4eeea0c6e196578ce12c","eba660cb825f4be49f9ff593b3b4aad1","c93a40507e1749038b3b64046664a4f5","c29f8d083fe14798a8b99070879a8082","06714d9ba00c476cb32dd90ae958f806","14a3c381b6e740c1be49076a00403bca","0f16406db931468baba33d924503a987","0d22aa7875bb4b98874c7179d9382dbf","43f867ea99034b0ebb59b1bdf01ac329","129510947fa249d0b2e87734df5e53d6","6fa581fd552c4c18b7d53f3c4b0e3a6a","7f1aa9d6074c43c8a59ae6e8ca12cd75","700c38f5a85444e389767fa327e553ed"]},"executionInfo":{"status":"ok","timestamp":1708187132594,"user_tz":-420,"elapsed":76084,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading Tokenizer...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ec9bd40e0684bb69eb5961e2a547c85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c9790f6f1af40c390b9126c729d3ae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3768c25a8f4e51822539b412ed0d70"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/vocab.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer_config.json\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d2d48a72574832950daeeb72ac074a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/vocab.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer_config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/en_tokenizer_bert-base-multilingual-cased/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/en_tokenizer_bert-base-multilingual-cased/special_tokens_map.json\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/vi_tokenizer_bert-base-multilingual-cased/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/vi_tokenizer_bert-base-multilingual-cased/special_tokens_map.json\n"]},{"output_type":"stream","name":"stdout","text":["Loading Model...\n"]},{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04b9ae4556d04d31ac24d2b2400d4c53"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/model.safetensors\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","Initializing bert-base-multilingual-cased as a decoder model. Cross attention layers are added to bert-base-multilingual-cased and randomly initialized if bert-base-multilingual-cased's architecture allows for cross attention layers.\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/model.safetensors\n","Generate config GenerationConfig {\n","  \"pad_token_id\": 0\n","}\n","\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertLMHeadModel: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n","- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertLMHeadModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.value.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Generation config file not found, using a generation config created from the model config.\n","Set `config.is_decoder=True` and `config.add_cross_attention=True` for decoder_config\n","Generate config GenerationConfig {}\n","\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 119547. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","<ipython-input-5-55d7a93299c1>:12: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 游뱅 Evaluate: https://huggingface.co/docs/evaluate\n","  self.bleu_metric = load_metric(\"sacrebleu\")\n"]},{"output_type":"stream","name":"stdout","text":["Loading Metric...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/sacrebleu/sacrebleu.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"117a1867471041178577a119e12a0102"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Check Save Model Path\n","Loading Dataset...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a726daf0a44640209e4e45ffecf7ab4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/181k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faad2b28d7e04177a44c49fccf1718fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading data:   0%|          | 0.00/181k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc6347a28f2947c2b1710f82ac92c364"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/133318 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61f89f0a224c441fa8be22680b3b3d0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/1269 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e058ffc0291f462eb0094cbb9be89fe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1269 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c93a40507e1749038b3b64046664a4f5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Setting finished.\n"]}],"source":["manager = Manager(cfg, is_train=True)"]},{"cell_type":"code","execution_count":8,"id":"2118d1b2","metadata":{"tags":[],"id":"2118d1b2","outputId":"76fe47cb-a838-462a-c1a8-c0908b6931b9","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1708196301432,"user_tz":-420,"elapsed":9168857,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"output_type":"stream","name":"stdout","text":["Training...\n"]},{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 133,318\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 41,665\n","  Number of trainable parameters = 384,194,811\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:639: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='41665' max='41665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [41665/41665 2:32:46, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu Score</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>2.123300</td>\n","      <td>2.013436</td>\n","      <td>20.708700</td>\n","      <td>35.848700</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.751700</td>\n","      <td>1.777506</td>\n","      <td>24.313800</td>\n","      <td>37.105600</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.537000</td>\n","      <td>1.698918</td>\n","      <td>25.693100</td>\n","      <td>36.330200</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.383200</td>\n","      <td>1.659009</td>\n","      <td>26.367800</td>\n","      <td>36.279700</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.272900</td>\n","      <td>1.660940</td>\n","      <td>26.304900</td>\n","      <td>36.713200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 1269\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 101,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 102,\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 75,\n","  \"min_length\": 25,\n","  \"no_repeat_ngram_size\": 3,\n","  \"pad_token_id\": 0\n","}\n","\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1473: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Saving model checkpoint to bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-8333\n","Configuration saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-8333/config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Removed shared tensor {'decoder.cls.predictions.decoder.bias', 'decoder.cls.predictions.decoder.weight'} while saving. This should be OK, but check by verifying that you don't receive any warning while reloading\n","Model weights saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-8333/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-8333/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-8333/special_tokens_map.json\n","/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:639: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","***** Running Evaluation *****\n","  Num examples = 1269\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Saving model checkpoint to bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-16666\n","Configuration saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-16666/config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Model weights saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-16666/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-16666/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-16666/special_tokens_map.json\n","/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:639: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","***** Running Evaluation *****\n","  Num examples = 1269\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Saving model checkpoint to bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-24999\n","Configuration saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-24999/config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Model weights saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-24999/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-24999/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-24999/special_tokens_map.json\n","/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:639: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","***** Running Evaluation *****\n","  Num examples = 1269\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Saving model checkpoint to bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-33332\n","Configuration saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-33332/config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Model weights saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-33332/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-33332/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-33332/special_tokens_map.json\n","/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:639: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","***** Running Evaluation *****\n","  Num examples = 1269\n","  Batch size = 8\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`.\n","  warnings.warn(\n","Saving model checkpoint to bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665\n","Configuration saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665/config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n","\n","Thrown during validation:\n","`num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n","Model weights saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665/pytorch_model.bin\n","tokenizer config file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665/tokenizer_config.json\n","Special tokens file saved in bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]}],"source":["manager.train()"]},{"cell_type":"markdown","source":["##5.Evaluate"],"metadata":{"id":"jx2jRxqdKjSO"},"id":"jx2jRxqdKjSO"},{"cell_type":"code","execution_count":9,"id":"724fa565","metadata":{"id":"724fa565","executionInfo":{"status":"ok","timestamp":1708196317445,"user_tz":-420,"elapsed":516,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["def load_model(cfg, checkpoint_name):\n","    # Load Tokenizer\n","    src_tokenizer_save_path = f\"{cfg.ckpt_dir}/{cfg.src_lang}_tokenizer_{cfg.src_model_name}\"\n","    src_tokenizer = BertTokenizerFast.from_pretrained(src_tokenizer_save_path)\n","\n","    tgt_tokenizer_save_path = f\"{cfg.ckpt_dir}/{cfg.tgt_lang}_tokenizer_{cfg.tgt_model_name}\"\n","    tgt_tokenizer = GPT2TokenizerFast.from_pretrained(tgt_tokenizer_save_path)\n","\n","    # Load Model\n","    model_save_path = f\"{cfg.ckpt_dir}/{checkpoint_name}\"\n","    model = EncoderDecoderModel.from_pretrained(model_save_path)\n","\n","    # Inference Param\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","    return src_tokenizer, tgt_tokenizer, model, device"]},{"cell_type":"code","execution_count":10,"id":"56f46712","metadata":{"id":"56f46712","executionInfo":{"status":"ok","timestamp":1708196321908,"user_tz":-420,"elapsed":682,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["from tqdm import tqdm\n","def inference(\n","    text,\n","    src_tokenizer,\n","    tgt_tokenizer,\n","    model,\n","    device=\"cpu\",\n","    max_length=75,\n","    beam_size=5\n","    ):\n","    inputs = src_tokenizer(\n","        text,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors=\"pt\"\n","        )\n","    input_ids = inputs.input_ids.to(device)\n","    attention_mask = inputs.attention_mask.to(device)\n","    model.to(device)\n","\n","    outputs = model.generate(\n","        input_ids,\n","        attention_mask=attention_mask,\n","        max_length=max_length,\n","        early_stopping=True,\n","        num_beams=beam_size,\n","        length_penalty=2.0\n","    )\n","\n","    output_str = tgt_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","\n","    return output_str\n","\n","def inference_bath(\n","    texts,\n","    src_tokenizer,\n","    tgt_tokenizer,\n","    model,\n","    device=\"cpu\",\n","    max_length=75,\n","    beam_size=5,\n","    batch_size=32\n","    ):\n","\n","    pred_texts = []\n","\n","    if len(texts) < batch_size:\n","        batch_size = len(texts)\n","\n","    for x in tqdm(range(0, len(texts), batch_size)):\n","        text = texts[x:x+batch_size]\n","\n","        inputs = src_tokenizer(\n","            text,\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=max_length,\n","            return_tensors=\"pt\"\n","            )\n","\n","        input_ids = inputs.input_ids.to(device)\n","        attention_mask = inputs.attention_mask.to(device)\n","        model.to(device)\n","\n","        outputs = model.generate(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            max_length=max_length,\n","            early_stopping=True,\n","            num_beams=beam_size,\n","            length_penalty=2.0\n","        )\n","\n","        output_str = tgt_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","        pred_texts.extend(output_str)\n","        torch.cuda.empty_cache()\n","\n","    return pred_texts"]},{"cell_type":"code","source":["class BaseConfig:\n","    \"\"\" base Encoder Decoder config \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        for k, v in kwargs.items():\n","            setattr(self, k, v)\n","\n","class NMTConfig(BaseConfig):\n","    # Data\n","    src_lang = 'en'\n","    tgt_lang = 'vi'\n","    src_max_len = 75\n","    tgt_max_len = 75\n","\n","    # Model\n","    src_model_name = \"bert-base-multilingual-cased\"\n","    tgt_model_name = \"bert-base-multilingual-cased\"\n","\n","    # Training\n","    load_model_from_path = False\n","    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","    learning_rate = 3e-5\n","    train_batch_size = 16\n","    eval_batch_size = 8\n","    num_train_epochs =15\n","    ckpt_dir = src_model_name + '_to_' + tgt_model_name\n","    use_eval_steps = False\n","    eval_steps = 2000\n","\n","    # Inference\n","    max_length_decoder = 75\n","    min_length_decoder = 25\n","    beam_size = 5\n","\n","cfg = NMTConfig()"],"metadata":{"id":"3KDuUw1r85Fi","executionInfo":{"status":"ok","timestamp":1708196333746,"user_tz":-420,"elapsed":1,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"id":"3KDuUw1r85Fi","execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":14,"id":"7f322730","metadata":{"id":"7f322730","executionInfo":{"status":"ok","timestamp":1708196351609,"user_tz":-420,"elapsed":3812,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}}},"outputs":[],"source":["data = load_dataset(\"mt_eng_vietnamese\", \"iwslt2015-en-vi\", split=\"test\")\n","src_texts = [sample[\"translation\"][\"en\"] for sample in data]\n","tgt_texts = [sample[\"translation\"][\"vi\"] for sample in data]"]},{"cell_type":"code","execution_count":15,"id":"7626fb56","metadata":{"id":"7626fb56","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708196403098,"user_tz":-420,"elapsed":7193,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}},"outputId":"5324f440-890e-407d-fcf2-c51d41ade1d7"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading file vocab.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","loading file vocab.json\n","loading file merges.txt\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n","The class this function is called from is 'GPT2TokenizerFast'.\n","loading configuration file bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665/config.json\n","Model config EncoderDecoderConfig {\n","  \"architectures\": [\n","    \"EncoderDecoderModel\"\n","  ],\n","  \"decoder\": {\n","    \"_name_or_path\": \"bert-base-multilingual-cased\",\n","    \"add_cross_attention\": true,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": true,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 119547\n","  },\n","  \"decoder_start_token_id\": 101,\n","  \"early_stopping\": true,\n","  \"encoder\": {\n","    \"_name_or_path\": \"bert-base-multilingual-cased\",\n","    \"add_cross_attention\": false,\n","    \"architectures\": [\n","      \"BertForMaskedLM\"\n","    ],\n","    \"attention_probs_dropout_prob\": 0.1,\n","    \"bad_words_ids\": null,\n","    \"begin_suppress_tokens\": null,\n","    \"bos_token_id\": null,\n","    \"chunk_size_feed_forward\": 0,\n","    \"classifier_dropout\": null,\n","    \"cross_attention_hidden_size\": null,\n","    \"decoder_start_token_id\": null,\n","    \"directionality\": \"bidi\",\n","    \"diversity_penalty\": 0.0,\n","    \"do_sample\": false,\n","    \"early_stopping\": false,\n","    \"encoder_no_repeat_ngram_size\": 0,\n","    \"eos_token_id\": null,\n","    \"exponential_decay_length_penalty\": null,\n","    \"finetuning_task\": null,\n","    \"forced_bos_token_id\": null,\n","    \"forced_eos_token_id\": null,\n","    \"hidden_act\": \"gelu\",\n","    \"hidden_dropout_prob\": 0.1,\n","    \"hidden_size\": 768,\n","    \"id2label\": {\n","      \"0\": \"LABEL_0\",\n","      \"1\": \"LABEL_1\"\n","    },\n","    \"initializer_range\": 0.02,\n","    \"intermediate_size\": 3072,\n","    \"is_decoder\": false,\n","    \"is_encoder_decoder\": false,\n","    \"label2id\": {\n","      \"LABEL_0\": 0,\n","      \"LABEL_1\": 1\n","    },\n","    \"layer_norm_eps\": 1e-12,\n","    \"length_penalty\": 1.0,\n","    \"max_length\": 20,\n","    \"max_position_embeddings\": 512,\n","    \"min_length\": 0,\n","    \"model_type\": \"bert\",\n","    \"no_repeat_ngram_size\": 0,\n","    \"num_attention_heads\": 12,\n","    \"num_beam_groups\": 1,\n","    \"num_beams\": 1,\n","    \"num_hidden_layers\": 12,\n","    \"num_return_sequences\": 1,\n","    \"output_attentions\": false,\n","    \"output_hidden_states\": false,\n","    \"output_scores\": false,\n","    \"pad_token_id\": 0,\n","    \"pooler_fc_size\": 768,\n","    \"pooler_num_attention_heads\": 12,\n","    \"pooler_num_fc_layers\": 3,\n","    \"pooler_size_per_head\": 128,\n","    \"pooler_type\": \"first_token_transform\",\n","    \"position_embedding_type\": \"absolute\",\n","    \"prefix\": null,\n","    \"problem_type\": null,\n","    \"pruned_heads\": {},\n","    \"remove_invalid_values\": false,\n","    \"repetition_penalty\": 1.0,\n","    \"return_dict\": true,\n","    \"return_dict_in_generate\": false,\n","    \"sep_token_id\": null,\n","    \"suppress_tokens\": null,\n","    \"task_specific_params\": null,\n","    \"temperature\": 1.0,\n","    \"tf_legacy_loss\": false,\n","    \"tie_encoder_decoder\": false,\n","    \"tie_word_embeddings\": true,\n","    \"tokenizer_class\": null,\n","    \"top_k\": 50,\n","    \"top_p\": 1.0,\n","    \"torch_dtype\": null,\n","    \"torchscript\": false,\n","    \"type_vocab_size\": 2,\n","    \"typical_p\": 1.0,\n","    \"use_bfloat16\": false,\n","    \"use_cache\": true,\n","    \"vocab_size\": 119547\n","  },\n","  \"eos_token_id\": 102,\n","  \"is_encoder_decoder\": true,\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 75,\n","  \"min_length\": 25,\n","  \"model_type\": \"encoder-decoder\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"pad_token_id\": 0,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.35.2\",\n","  \"vocab_size\": 119547\n","}\n","\n","loading weights file bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665/model.safetensors\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:418: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:437: UserWarning: `num_beams` is set to 1. However, `length_penalty` is set to `2.0` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `length_penalty`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n","  warnings.warn(\n","Generate config GenerationConfig {\n","  \"decoder_start_token_id\": 101,\n","  \"early_stopping\": true,\n","  \"eos_token_id\": 102,\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 75,\n","  \"min_length\": 25,\n","  \"no_repeat_ngram_size\": 3,\n","  \"pad_token_id\": 0\n","}\n","\n","Generate config GenerationConfig {\n","  \"pad_token_id\": 0\n","}\n","\n","All model checkpoint weights were used when initializing EncoderDecoderModel.\n","\n","All the weights of EncoderDecoderModel were initialized from the model checkpoint at bert-base-multilingual-cased_to_bert-base-multilingual-cased/checkpoint-41665.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n","Generation config file not found, using a generation config created from the model config.\n"]}],"source":["src_tokenizer, tgt_tokenizer, model, device = load_model(cfg, checkpoint_name=\"checkpoint-41665\")"]},{"cell_type":"code","source":["pred_texts = inference_bath(src_texts, src_tokenizer, tgt_tokenizer, model, device, beam_size=1)"],"metadata":{"id":"qWHg9XUiDvzz"},"id":"qWHg9XUiDvzz","execution_count":null,"outputs":[]},{"cell_type":"code","source":["sacrebleu.corpus_bleu(pred_texts, [tgt_texts])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nu-fXb7pETXi","executionInfo":{"status":"ok","timestamp":1708196481840,"user_tz":-420,"elapsed":724,"user":{"displayName":"Th치i Nguy敲n Qu敲녂","userId":"04072932238722635186"}},"outputId":"f0a1bd7f-d9d9-4166-e156-20bd05ddeb34"},"id":"Nu-fXb7pETXi","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BLEU = 25.41 53.8/31.8/19.8/12.3 (BP = 1.000 ratio = 1.136 hyp_len = 38315 ref_len = 33738)"]},"metadata":{},"execution_count":17}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"},"colab":{"provenance":[],"toc_visible":true,"gpuClass":"premium"},"accelerator":"GPU","gpuClass":"premium","widgets":{"application/vnd.jupyter.widget-state+json":{"8ec9bd40e0684bb69eb5961e2a547c85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5d0396b517b44f29a6dd1db67e90eed","IPY_MODEL_a5ea01cb256049eb9d9f888616725f60","IPY_MODEL_237bb8d7735448deb76a7b98dbbc3147"],"layout":"IPY_MODEL_baf9ed9be5384c0496e15150dbcfc808"}},"a5d0396b517b44f29a6dd1db67e90eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65f43b262abb43ebb8a89cdbec780f34","placeholder":"","style":"IPY_MODEL_6320d65752f74c76b5e93c25edfe508e","value":"tokenizer_config.json:100%"}},"a5ea01cb256049eb9d9f888616725f60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f516628305924da9874f624d72e9c99f","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9bc6b01585b747b89f9aebf73b7795c4","value":29}},"237bb8d7735448deb76a7b98dbbc3147":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8610e699e1645a1bc9dd40740ecd377","placeholder":"","style":"IPY_MODEL_27afd50ff61742d8947a5d1215b9f357","value":"29.0/29.0[00:00&lt;00:00,2.47kB/s]"}},"baf9ed9be5384c0496e15150dbcfc808":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65f43b262abb43ebb8a89cdbec780f34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6320d65752f74c76b5e93c25edfe508e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f516628305924da9874f624d72e9c99f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bc6b01585b747b89f9aebf73b7795c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8610e699e1645a1bc9dd40740ecd377":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27afd50ff61742d8947a5d1215b9f357":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c9790f6f1af40c390b9126c729d3ae5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f1fe71e174d4050b002267cb20f85d9","IPY_MODEL_df78999befef439b839daccc30bbb527","IPY_MODEL_a4ca6d9107ed4b5a8303460281611fb0"],"layout":"IPY_MODEL_58b5c51d02b2446fbdeb99e09409bf1f"}},"8f1fe71e174d4050b002267cb20f85d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_863d0bd13ecd478cb7e40c5c5ac68dd7","placeholder":"","style":"IPY_MODEL_8c72650f6e92450cb1fc621d59b2d636","value":"vocab.txt:100%"}},"df78999befef439b839daccc30bbb527":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf6a864db3864922a6d0562fbdeda4bc","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4152f23a75848f48c48c96ddb4d2fcc","value":995526}},"a4ca6d9107ed4b5a8303460281611fb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eadbe6e43d07446d8132a4fa1d0faedf","placeholder":"","style":"IPY_MODEL_91af7ce0a1f1498888871bd47f854618","value":"996k/996k[00:00&lt;00:00,36.4MB/s]"}},"58b5c51d02b2446fbdeb99e09409bf1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"863d0bd13ecd478cb7e40c5c5ac68dd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c72650f6e92450cb1fc621d59b2d636":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf6a864db3864922a6d0562fbdeda4bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4152f23a75848f48c48c96ddb4d2fcc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eadbe6e43d07446d8132a4fa1d0faedf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91af7ce0a1f1498888871bd47f854618":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a3768c25a8f4e51822539b412ed0d70":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b2b7e1788a144fc80b06a3342402c53","IPY_MODEL_9efdcf9d4af14535bfb4b872acbfc1ab","IPY_MODEL_78f0fcb8cefd488d8fd489792a547556"],"layout":"IPY_MODEL_b2721479ab96432d8e4c27a66165a331"}},"3b2b7e1788a144fc80b06a3342402c53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_136fdace19284b718a7e434afb767fbf","placeholder":"","style":"IPY_MODEL_08ecb6a1b3ee473cbc322ec5d910f2cc","value":"tokenizer.json:100%"}},"9efdcf9d4af14535bfb4b872acbfc1ab":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0119e423ccd14a6fa123cd033c12b382","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8cb16a5aa5d84a7f9ff6091d34e109b7","value":1961828}},"78f0fcb8cefd488d8fd489792a547556":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62691a2f4d424aa28d02648b8631e42a","placeholder":"","style":"IPY_MODEL_4396f568e0e94f6ea4bd6782b3929a00","value":"1.96M/1.96M[00:00&lt;00:00,2.66MB/s]"}},"b2721479ab96432d8e4c27a66165a331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"136fdace19284b718a7e434afb767fbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08ecb6a1b3ee473cbc322ec5d910f2cc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0119e423ccd14a6fa123cd033c12b382":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cb16a5aa5d84a7f9ff6091d34e109b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62691a2f4d424aa28d02648b8631e42a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4396f568e0e94f6ea4bd6782b3929a00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8d2d48a72574832950daeeb72ac074a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed09a42689e94bb99fef042760441258","IPY_MODEL_246371b3ff5b47adadb74fd748faad97","IPY_MODEL_e8d8cda868e14fcda5411827ab972f48"],"layout":"IPY_MODEL_e14447fc708641d0877763d7ada72e9b"}},"ed09a42689e94bb99fef042760441258":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67d6af9ec5f8447485a68bf73bd2ef06","placeholder":"","style":"IPY_MODEL_9ed49c76dd934036822a22a22b31c8be","value":"config.json:100%"}},"246371b3ff5b47adadb74fd748faad97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47745f113d16493ba57d3d84b7b37846","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9f6f6c959664385aea8781858c21172","value":625}},"e8d8cda868e14fcda5411827ab972f48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_89abf96e583f4fe3935b73c2b13bc0fa","placeholder":"","style":"IPY_MODEL_da256cab8e1f49ec99257c5daadcb795","value":"625/625[00:00&lt;00:00,46.6kB/s]"}},"e14447fc708641d0877763d7ada72e9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67d6af9ec5f8447485a68bf73bd2ef06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ed49c76dd934036822a22a22b31c8be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47745f113d16493ba57d3d84b7b37846":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9f6f6c959664385aea8781858c21172":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"89abf96e583f4fe3935b73c2b13bc0fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da256cab8e1f49ec99257c5daadcb795":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04b9ae4556d04d31ac24d2b2400d4c53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_642bdb53ea4c434485c382c7827f15ef","IPY_MODEL_d233b89b47424f55ae63dc86e71fbad5","IPY_MODEL_cc55c5b310b443198eeff939175ba244"],"layout":"IPY_MODEL_5822736dcf614680add01abee3dd1285"}},"642bdb53ea4c434485c382c7827f15ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b2059bf1c84b97b21dbbfdea58123a","placeholder":"","style":"IPY_MODEL_577fa092c335498b985109cfad6012af","value":"model.safetensors:100%"}},"d233b89b47424f55ae63dc86e71fbad5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_256dbce836fc41e8952d49588e3d381e","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2e16b502b8d41129019f817581e597a","value":714290682}},"cc55c5b310b443198eeff939175ba244":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d40ccee378fb4b6c93bd0e683e010e93","placeholder":"","style":"IPY_MODEL_bf0eacaa9f0948899197ff6bf242c2df","value":"714M/714M[00:02&lt;00:00,251MB/s]"}},"5822736dcf614680add01abee3dd1285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6b2059bf1c84b97b21dbbfdea58123a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"577fa092c335498b985109cfad6012af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"256dbce836fc41e8952d49588e3d381e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2e16b502b8d41129019f817581e597a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d40ccee378fb4b6c93bd0e683e010e93":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf0eacaa9f0948899197ff6bf242c2df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"117a1867471041178577a119e12a0102":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_787c08d264c941c28c702046ada38291","IPY_MODEL_1f5cef4b3daa4c688585e955ea9600f3","IPY_MODEL_410d3d7a70f2451ead0686bf0888abe2"],"layout":"IPY_MODEL_51cd0825bda84515bc8aa2f20195fc1a"}},"787c08d264c941c28c702046ada38291":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df13e35455e341d89a87a251fa09dc3c","placeholder":"","style":"IPY_MODEL_6c5fb78927c946978d131a17fde72763","value":"Downloadingbuilderscript:"}},"1f5cef4b3daa4c688585e955ea9600f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cead66be57349faafe328ecd513e0f5","max":2849,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b235face4090455abf8a823ba4b2a65c","value":2849}},"410d3d7a70f2451ead0686bf0888abe2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77731caf83e8469ab5b3d7ee7344d3ee","placeholder":"","style":"IPY_MODEL_5eff238c117f4e169d3242de6b250cc2","value":"7.65k/?[00:00&lt;00:00,544kB/s]"}},"51cd0825bda84515bc8aa2f20195fc1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df13e35455e341d89a87a251fa09dc3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c5fb78927c946978d131a17fde72763":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1cead66be57349faafe328ecd513e0f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b235face4090455abf8a823ba4b2a65c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77731caf83e8469ab5b3d7ee7344d3ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eff238c117f4e169d3242de6b250cc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a726daf0a44640209e4e45ffecf7ab4c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e1f97e7cbfd6470da83de3a9ac06b5f7","IPY_MODEL_8a9903588be84c7680901d88367e1a5b","IPY_MODEL_d9be5377b9084a65b07fdf9dbede434e"],"layout":"IPY_MODEL_04cfa0e8b35d4cd690738a5fcd43d48c"}},"e1f97e7cbfd6470da83de3a9ac06b5f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_547ebb48ce664bb9a9ad1af05852320f","placeholder":"","style":"IPY_MODEL_42a9b3ce657649fcb8a14f8dc81cb4ca","value":"Downloadingdata:100%"}},"8a9903588be84c7680901d88367e1a5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1612378c0484914ab6fd36608030e14","max":17777840,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a16aaa8e73d4a98b3c803d6f7024c68","value":17777840}},"d9be5377b9084a65b07fdf9dbede434e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ace9caa4277245be9d181f7d04cdda20","placeholder":"","style":"IPY_MODEL_c687347942ef41939423628af1ea2036","value":"17.8M/17.8M[00:00&lt;00:00,21.4MB/s]"}},"04cfa0e8b35d4cd690738a5fcd43d48c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"547ebb48ce664bb9a9ad1af05852320f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42a9b3ce657649fcb8a14f8dc81cb4ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1612378c0484914ab6fd36608030e14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a16aaa8e73d4a98b3c803d6f7024c68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ace9caa4277245be9d181f7d04cdda20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c687347942ef41939423628af1ea2036":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faad2b28d7e04177a44c49fccf1718fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21c5bef2ce0348ecbb8e13888db44657","IPY_MODEL_fc86b011b2554cd2a36e4cc7fb8a0682","IPY_MODEL_ca503beae4e9495295ea37e95fb50ef8"],"layout":"IPY_MODEL_36721a951dec414aa9316278d511d751"}},"21c5bef2ce0348ecbb8e13888db44657":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb37abb3142b467983df816d71734401","placeholder":"","style":"IPY_MODEL_933c05f7d1cb414b9ec11088c58bcfd6","value":"Downloadingdata:100%"}},"fc86b011b2554cd2a36e4cc7fb8a0682":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43f96e2da6db44b8b3b41ff7351db172","max":180642,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12ce7c70aced41d7aa1fbee673dda4bd","value":180642}},"ca503beae4e9495295ea37e95fb50ef8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db0082eef7c3477bb8e8dc3da73fde37","placeholder":"","style":"IPY_MODEL_c0297cc040394ec7afeaf7d813c86b57","value":"181k/181k[00:00&lt;00:00,652kB/s]"}},"36721a951dec414aa9316278d511d751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb37abb3142b467983df816d71734401":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"933c05f7d1cb414b9ec11088c58bcfd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43f96e2da6db44b8b3b41ff7351db172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"12ce7c70aced41d7aa1fbee673dda4bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db0082eef7c3477bb8e8dc3da73fde37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0297cc040394ec7afeaf7d813c86b57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc6347a28f2947c2b1710f82ac92c364":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92216fdc65db4010b65d5a576f185a96","IPY_MODEL_9a9cb72eb8a14e118aea9fa66e2cd465","IPY_MODEL_b6baf914a86a4e20baf797bf12a18b73"],"layout":"IPY_MODEL_d8be81037a6943afa285c7d2fcfef136"}},"92216fdc65db4010b65d5a576f185a96":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ad48a346ce64799a7b68b6c2395e884","placeholder":"","style":"IPY_MODEL_246ecc92d2f34eab816d804bf6209e46","value":"Downloadingdata:100%"}},"9a9cb72eb8a14e118aea9fa66e2cd465":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8361d37640ef42fda3734a7f9f9a62d1","max":180642,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7561171fabfc4230ae00be38bfced54f","value":180642}},"b6baf914a86a4e20baf797bf12a18b73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f2047b289f1457395c3b43d23eb88a6","placeholder":"","style":"IPY_MODEL_8568d83d656e4d588db280ce6b01af8e","value":"181k/181k[00:00&lt;00:00,246kB/s]"}},"d8be81037a6943afa285c7d2fcfef136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ad48a346ce64799a7b68b6c2395e884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"246ecc92d2f34eab816d804bf6209e46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8361d37640ef42fda3734a7f9f9a62d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7561171fabfc4230ae00be38bfced54f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f2047b289f1457395c3b43d23eb88a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8568d83d656e4d588db280ce6b01af8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61f89f0a224c441fa8be22680b3b3d0a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ad1a61e94054c75802d7626ea26daae","IPY_MODEL_e4c111798b164d2a812f30b488aaaf1d","IPY_MODEL_ebad4741511d402cb539ab31b5626043"],"layout":"IPY_MODEL_8dfc21ca5d8544febd1162ba25ee9a2f"}},"4ad1a61e94054c75802d7626ea26daae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d413a464a5c40879207012c9cbd29e9","placeholder":"","style":"IPY_MODEL_125f1e821bfb4f42a4e4fbe4ea79b8ab","value":"Generatingtrainsplit:100%"}},"e4c111798b164d2a812f30b488aaaf1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_496dbe2140a842bda7ec953b423253d5","max":133318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e3576804e524e6db3cba29f6f114c5f","value":133318}},"ebad4741511d402cb539ab31b5626043":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a975156302842588b2811f45cf13cac","placeholder":"","style":"IPY_MODEL_bd5130966d25440894d69bd7ab522a92","value":"133318/133318[00:00&lt;00:00,845079.05examples/s]"}},"8dfc21ca5d8544febd1162ba25ee9a2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d413a464a5c40879207012c9cbd29e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"125f1e821bfb4f42a4e4fbe4ea79b8ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"496dbe2140a842bda7ec953b423253d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e3576804e524e6db3cba29f6f114c5f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a975156302842588b2811f45cf13cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd5130966d25440894d69bd7ab522a92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e058ffc0291f462eb0094cbb9be89fe8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_231378acab0042abae76b1852f422510","IPY_MODEL_34c0065d91af4f85aa2a85192ceacf0c","IPY_MODEL_c84fdd5ca2e14b13b729a54a8aed20bc"],"layout":"IPY_MODEL_6499c3e271c4445189f001d04d65b187"}},"231378acab0042abae76b1852f422510":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_afb14a37bec14dcaaef9e2e0e339b9ef","placeholder":"","style":"IPY_MODEL_237486d0561a406aa00eb1e05d5d7e38","value":"Generatingvalidationsplit:100%"}},"34c0065d91af4f85aa2a85192ceacf0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd3ffb8751b04decb617d0fe21671f35","max":1269,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33cb80778dff40979ee383539d3ca581","value":1269}},"c84fdd5ca2e14b13b729a54a8aed20bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a493153e1ff4eeea0c6e196578ce12c","placeholder":"","style":"IPY_MODEL_eba660cb825f4be49f9ff593b3b4aad1","value":"1269/1269[00:00&lt;00:00,79327.71examples/s]"}},"6499c3e271c4445189f001d04d65b187":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afb14a37bec14dcaaef9e2e0e339b9ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"237486d0561a406aa00eb1e05d5d7e38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd3ffb8751b04decb617d0fe21671f35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33cb80778dff40979ee383539d3ca581":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a493153e1ff4eeea0c6e196578ce12c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eba660cb825f4be49f9ff593b3b4aad1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c93a40507e1749038b3b64046664a4f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c29f8d083fe14798a8b99070879a8082","IPY_MODEL_06714d9ba00c476cb32dd90ae958f806","IPY_MODEL_14a3c381b6e740c1be49076a00403bca"],"layout":"IPY_MODEL_0f16406db931468baba33d924503a987"}},"c29f8d083fe14798a8b99070879a8082":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d22aa7875bb4b98874c7179d9382dbf","placeholder":"","style":"IPY_MODEL_43f867ea99034b0ebb59b1bdf01ac329","value":"Generatingtestsplit:100%"}},"06714d9ba00c476cb32dd90ae958f806":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_129510947fa249d0b2e87734df5e53d6","max":1269,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fa581fd552c4c18b7d53f3c4b0e3a6a","value":1269}},"14a3c381b6e740c1be49076a00403bca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f1aa9d6074c43c8a59ae6e8ca12cd75","placeholder":"","style":"IPY_MODEL_700c38f5a85444e389767fa327e553ed","value":"1269/1269[00:00&lt;00:00,73028.99examples/s]"}},"0f16406db931468baba33d924503a987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d22aa7875bb4b98874c7179d9382dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43f867ea99034b0ebb59b1bdf01ac329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"129510947fa249d0b2e87734df5e53d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fa581fd552c4c18b7d53f3c4b0e3a6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f1aa9d6074c43c8a59ae6e8ca12cd75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"700c38f5a85444e389767fa327e553ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}